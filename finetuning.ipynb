{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: resnet50-tensorflow12-0200.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-0dd1ca0cfb2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# Load pre-trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;31m# Freeze all layers but the last one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfreeze_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-0dd1ca0cfb2e>\u001b[0m in \u001b[0;36mload_pretrained_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model is available, sorry'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfreeze_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     81\u001b[0m                   (export_dir,\n\u001b[1;32m     82\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: resnet50-tensorflow12-0200.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "from keras.backend import backend\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "    \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "# CIFAR-10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
    "# training set: 10 classes with 5000 samples each (50,000 samples total)\n",
    "# test set: 10 classes with 1000 samples each (10,000 samples total)\n",
    "nb_classes=10\n",
    "\n",
    "first_class=1 \n",
    "second_class=7\n",
    "nb_samples=5000\n",
    "nb_samples_test=1000\n",
    "\n",
    "nb_epochs=10\n",
    "\n",
    "nb_gpus=1\n",
    "batch=32\n",
    "\n",
    "def get_gpus(count):\n",
    "    gpu_list = []\n",
    "    for i in range(count): \n",
    "        gpu_list.append('gpu(%d)' % i)\n",
    "    return gpu_list\n",
    "\n",
    "def normalize_samples(x):\n",
    "    # Divide pixel values by 255 to obtain a a float value between 0 and 1\n",
    "    x = x.astype('float32')\n",
    "    x /= 255\n",
    "    return x\n",
    "\n",
    "def get_samples(x, y, cifar10_class, count):\n",
    "    # Find indexes of labels matching the right category\n",
    "    y_indexes = np.where(y == cifar10_class)[0]\n",
    "    # Take the 'count' first indexes\n",
    "    y_indexes = y_indexes[:count]\n",
    "    # Extract samples and labels for these indexes\n",
    "    y_samples = y[y_indexes]\n",
    "    x_samples = x[y_indexes] \n",
    "    # Normalize pixel values (this is how the model was trained)\n",
    "    x_samples = normalize_samples(x_samples)\n",
    "    return x_samples, y_samples\n",
    "\n",
    "def prepare_dataset(x, y):\n",
    "    # Get 'nb_samples' samples and labels for first category\n",
    "    x0, y0 = get_samples(x, y, first_class, nb_samples)\n",
    "    # Get 'nb_samples' samples and labels for second category\n",
    "    x1, y1 = get_samples(x, y, second_class, nb_samples)\n",
    "    # Build the sample dataset\n",
    "    X = np.concatenate((x0, x1))\n",
    "    # Build the label dataset\n",
    "    Y = np.concatenate((y0, y1))\n",
    "    Y = np_utils.to_categorical(Y, nb_classes) # One-hot encode the category\n",
    "    return X,Y\n",
    "\n",
    "def set_tensorflow_config():\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    #config.gpu_options.per_process_gpu_memory_fraction = 0.9 \n",
    "    config.gpu_options.visible_device_list = \",\".join(str(i) for i in range(nb_gpus))\n",
    "    K.set_session(tf.compat.v1.Session(config=config))\n",
    "\n",
    "def load_pretrained_model():\n",
    "    if backend()=='mxnet':\n",
    "        model = 'resnet50-mxnet011rc3-0200.h5'\n",
    "    elif backend()=='tensorflow':\n",
    "        set_tensorflow_config()\n",
    "        model = 'resnet50-tensorflow12-0200.h5'\n",
    "    else:\n",
    "        print('No model is available, sorry')\n",
    "        exit()\n",
    "    return load_model(model)\n",
    "\n",
    "def freeze_layers(model):\n",
    "    for layer in model.layers[0:-1]:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load training and test samples for CIFAR-10\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    # Prepare subsets for training and test\n",
    "    X, Y = prepare_dataset(x_train, y_train)\n",
    "    X_test, Y_test = prepare_dataset(x_test, y_test)\n",
    "\n",
    "    # Load pre-trained model\n",
    "    model = load_pretrained_model()\n",
    "    # Freeze all layers but the last one\n",
    "    model = freeze_layers(model)\n",
    "    # Prepare model for retraining\n",
    "    #opt = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    opt = 'adagrad'\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'], context=get_gpus(nb_gpus))\n",
    "\n",
    "    # Evaluate base model accuracy on the test subset\n",
    "    scores = model.evaluate(X_test, Y_test, batch_size=batch, verbose=1)\n",
    "    print(scores)\n",
    "    # Retrain model on the training subset\n",
    "    model.fit(X, Y, batch_size=batch, shuffle=True, nb_epoch=nb_epochs, validation_data=(X_test, Y_test), verbose=1)\n",
    "    # Evaluate retrained model accuracy on the test subset\n",
    "    scores = model.evaluate(X_test, Y_test, batch_size=batch, verbose=1)\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
