{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(trainX, trainY), (testX, testY) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    #load dataset\n",
    "    (trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "    #encode target values\n",
    "    trainY = to_categorical(trainY)\n",
    "    testY = to_categorical(testY)\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(train, test):\n",
    "    # convert to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    # normalize- range 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    return train_norm, test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/hyperopt/hyperopt.git\n",
      "  Cloning https://github.com/hyperopt/hyperopt.git to /private/var/folders/v_/8s4s4snx4rn719x9kf1s6s080000gn/T/pip-req-build-vugymj2f\n",
      "  Running command git clone -q https://github.com/hyperopt/hyperopt.git /private/var/folders/v_/8s4s4snx4rn719x9kf1s6s080000gn/T/pip-req-build-vugymj2f\n",
      "  Running command git submodule update --init --recursive -q\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.7/site-packages (from hyperopt==0.2.7) (1.21.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.7/site-packages (from hyperopt==0.2.7) (1.4.1)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.7/site-packages (from hyperopt==0.2.7) (1.12.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/anaconda3/lib/python3.7/site-packages (from hyperopt==0.2.7) (2.3)\n",
      "Requirement already satisfied: future in /opt/anaconda3/lib/python3.7/site-packages (from hyperopt==0.2.7) (0.17.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.7/site-packages (from hyperopt==0.2.7) (4.36.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/anaconda3/lib/python3.7/site-packages (from hyperopt==0.2.7) (1.2.2)\n",
      "Collecting py4j (from hyperopt==0.2.7)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/30/a58b32568f1623aaad7db22aa9eafc4c6c194b429ff35bdc55ca2726da47/py4j-0.10.9.7-py2.py3-none-any.whl (200kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 9.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator>=4.3.0 in /opt/anaconda3/lib/python3.7/site-packages (from networkx>=2.2->hyperopt==0.2.7) (4.4.0)\n",
      "Building wheels for collected packages: hyperopt\n",
      "  Building wheel for hyperopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hyperopt: filename=hyperopt-0.2.7-py2.py3-none-any.whl size=966119 sha256=dc761b3419c67a0e61cadd97d8a1bf64a48bf870fdaf99603314e532d32293f0\n",
      "  Stored in directory: /private/var/folders/v_/8s4s4snx4rn719x9kf1s6s080000gn/T/pip-ephem-wheel-cache-40vnx6tf/wheels/41/81/24/15fcba6ebbe35fc157f711f37249cbf4229bb3754ff607fd21\n",
      "Successfully built hyperopt\n",
      "Installing collected packages: py4j, hyperopt\n",
      "Successfully installed hyperopt-0.2.7 py4j-0.10.9.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/hyperopt/hyperopt.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:                                      \n",
      "{'conv_kernel_size': 3, 'dropout_prob': 0.15884064221945612, 'optimizer': 'Adam'}\n",
      "Accuracy:                                             \n",
      "0.10159999877214432                                   \n",
      "----------------------------------------------------  \n",
      "Hyperparameters:                                                                  \n",
      "{'conv_kernel_size': 1, 'dropout_prob': 0.18858814375613153, 'optimizer': 'sgd'}  \n",
      "Accuracy:                                                                         \n",
      "0.10109999775886536                                                               \n",
      "----------------------------------------------------                              \n",
      "Hyperparameters:                                                                  \n",
      "{'conv_kernel_size': 3, 'dropout_prob': 0.2954079963786884, 'optimizer': 'Adam'}  \n",
      "Accuracy:                                                                         \n",
      "0.10249999910593033                                                               \n",
      "----------------------------------------------------                              \n",
      "Hyperparameters:                                                                  \n",
      "{'conv_kernel_size': 3, 'dropout_prob': 0.13003919268397987, 'optimizer': 'sgd'}  \n",
      "Accuracy:                                                                         \n",
      "0.09790000319480896                                                               \n",
      "----------------------------------------------------                              \n",
      "Hyperparameters:                                                                  \n",
      "{'conv_kernel_size': 1, 'dropout_prob': 0.12806301031114153, 'optimizer': 'sgd'}  \n",
      "Accuracy:                                                                         \n",
      "0.17020000517368317                                                               \n",
      "----------------------------------------------------                              \n",
      "Hyperparameters:                                                                  \n",
      "{'conv_kernel_size': 3, 'dropout_prob': 0.1171055327264785, 'optimizer': 'sgd'}   \n",
      "Accuracy:                                                                         \n",
      "0.10010000318288803                                                               \n",
      "----------------------------------------------------                              \n",
      "Hyperparameters:                                                                  \n",
      "{'conv_kernel_size': 3, 'dropout_prob': 0.31897005402662215, 'optimizer': 'Adam'} \n",
      "Accuracy:                                                                         \n",
      "0.10029999911785126                                                               \n",
      "----------------------------------------------------                              \n",
      "Hyperparameters:                                                                  \n",
      "{'conv_kernel_size': 3, 'dropout_prob': 0.2605408224876211, 'optimizer': 'Adam'}  \n",
      "Accuracy:                                                                         \n",
      "0.10159999877214432                                                               \n",
      "----------------------------------------------------                              \n",
      "Hyperparameters:                                                                  \n",
      "{'conv_kernel_size': 5, 'dropout_prob': 0.2518225357800308, 'optimizer': 'sgd'}   \n",
      "Accuracy:                                                                         \n",
      "0.09989999979734421                                                               \n",
      "----------------------------------------------------                              \n",
      "Hyperparameters:                                                                  \n",
      "{'conv_kernel_size': 3, 'dropout_prob': 0.1765014323742451, 'optimizer': 'Adam'}  \n",
      "Accuracy:                                                                         \n",
      "0.09769999980926514                                                               \n",
      "----------------------------------------------------                              \n",
      "100%|██████████| 10/10 [10:20<00:00, 62.10s/trial, best loss: -0.17020000517368317]\n",
      "==================================\n",
      "Best Hyperparameters {'conv_kernel_size': 0, 'dropout_prob': 0.12806301031114153, 'optimizer': 1}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cf4bd3562701>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best Hyperparameters\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mtest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mperformance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_fashion_images_3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_fashion_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def optimize_cnn(hyperparameter):\n",
    "  # Define model using hyperparameters \n",
    "  cnn_model = Sequential([Conv2D(32, kernel_size=hyperparameter['conv_kernel_size'], activation='relu',\n",
    "                                 input_shape=(32,32,3)), \n",
    "            MaxPooling2D(pool_size=(2,2)),\n",
    "            Dropout(hyperparameter['dropout_prob']),\n",
    "            Conv2D(64, kernel_size=hyperparameter['conv_kernel_size'], activation='relu'),\n",
    "            MaxPooling2D(pool_size=(2,2)),\n",
    "            Dropout(hyperparameter['dropout_prob']), \n",
    "            Flatten(),\n",
    "            Dense(32, activation='relu'), \n",
    "            Dense(10, activation='softmax'),])\n",
    "\n",
    "    cnn_model.compile(optimizer=hyperparameter['optimizer'], loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    cnn_model.fit(train_X, to_categorical(train_y), epochs=2, batch_size=256, verbose=0)\n",
    " \n",
    "  performance = cnn_model.evaluate(valid_X, to_categorical(valid_y), verbose=0)\n",
    "\n",
    "  print(\"Hyperparameters: \", hyperparameter, \"Accuracy: \", performance[1])\n",
    "  print(\"----------------------------------------------------\")\n",
    "  # We want to minimize loss i.e. negative of accuracy\n",
    "  return({\"status\": STATUS_OK, \"loss\": -1*performance[1], \"model\":cnn_model})\n",
    "  \n",
    "train_X, train_y = trainX[:50000], trainY[:50000]\n",
    "valid_X, valid_y = trainX[-10000:],trainY[-10000:]\n",
    "\n",
    "# Define search space for hyper-parameters\n",
    "space = {\n",
    "    \n",
    "    'conv_kernel_size': hp.choice('conv_kernel_size', [1, 3, 5]),\n",
    "\n",
    "    'dropout_prob': hp.uniform('dropout_prob', 0.1, 0.35),\n",
    "\n",
    "    'optimizer': hp.choice('optimizer', ['Adam', 'sgd']),\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(\n",
    "        optimize_cnn,\n",
    "        space,\n",
    "        algo=tpe.suggest,\n",
    "        trials=trials,\n",
    "        max_evals=10,\n",
    "    )\n",
    "\n",
    "import numpy as np\n",
    "print(\"==================================\")\n",
    "print(\"Best Hyperparameters\", best)\n",
    "\n",
    "test_model = trials.results[np.argmin([r['loss'] for r in trials.results])]['model']\n",
    "\n",
    "performance = test_model.evaluate(trainX, to_categorical(trainY))\n",
    "\n",
    "print(\"==================================\")\n",
    "print(\"Test Accuracy: \", performance[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "Best Hyperparameters {'conv_kernel_size': 0, 'dropout_prob': 0.12806301031114153, 'optimizer': 1}\n",
      "50000/50000 [==============================] - 27s 541us/step\n",
      "==================================\n",
      "Test Accuracy:  0.16553999483585358\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"==================================\")\n",
    "print(\"Best Hyperparameters\", best)\n",
    "\n",
    "test_model = trials.results[np.argmin([r['loss'] for r in trials.results])]['model']\n",
    "\n",
    "performance = test_model.evaluate(trainX, to_categorical(trainY))\n",
    "\n",
    "print(\"==================================\")\n",
    "print(\"Test Accuracy: \", performance[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
